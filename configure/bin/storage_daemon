#!/usr/bin/env python
#
# ==============================
# Copyright 2011 Whamcloud, Inc.
# ==============================

import sys
import os
bin_dir = os.path.abspath(os.path.dirname(sys.modules['__main__'].__file__))
project_dir = "/" + os.path.join(*(bin_dir.split(os.sep)[0:-2]))
sys.path.append(project_dir)

from django.core.management import setup_environ
import settings
setup_environ(settings)

import signal
import logging
import os
import threading
import time
import datetime
from django.db import transaction

daemon_log = logging.getLogger('storage_daemon')
daemon_log.setLevel(logging.DEBUG)
handler = logging.FileHandler(os.path.join(settings.LOG_PATH, "storage_daemon.log"))
handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%d/%b/%Y:%H:%M:%S'))
daemon_log.addHandler(handler)
if settings.DEBUG:
    daemon_log.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%d/%b/%Y:%H:%M:%S'))
    daemon_log.addHandler(handler)
else:
    daemon_log.setLevel(logging.WARNING)

# Thread-per-session is just a convenient way of coding this.  The actual required
# behaviour is for a session to always run in the same process.  So we could
# equally use a thread pool for advancing the loop of each session, or we
# could use a multiprocessing pool as long as a session is always advanced
# in the same worker process.
class PluginSession(threading.Thread):
    def __init__(self, root_resource_id, *args, **kwargs):
        self.stopping = False
        self.finished = False
        self.root_resource_id = root_resource_id

        super(PluginSession, self).__init__(*args, **kwargs)

    def run(self):
        from configure.lib.storage_plugin.query import ResourceQuery
        from configure.lib.storage_plugin.manager import storage_plugin_manager
        from configure.models import StorageResourceRecord
        record = StorageResourceRecord.objects.get(id=self.root_resource_id)
        plugin_klass = storage_plugin_manager.get_plugin_class(
                          record.resource_class.storage_plugin.module_name)
        root_resource = ResourceQuery().get_resource(record)

        RETRY_DELAY_MIN = 1
        RETRY_DELAY_MAX = 256
        retry_delay = RETRY_DELAY_MIN
        while not self.stopping:
            last_retry = datetime.datetime.now()
            try:
                self._scan_loop(plugin_klass, root_resource)
            except Exception:
                run_duration = datetime.datetime.now() - last_retry
                if last_retry and run_duration > datetime.timedelta(seconds = RETRY_DELAY_MAX):
                    # If the last run was long running (i.e. probably ran okay until something went
                    # wrong) then retry quickly.
                    retry_delay = RETRY_DELAY_MIN
                else:
                    # If we've already retried recently, then start backing off.
                    retry_delay *= 2

                daemon_log.warning("Exception in scan loop for resource %s, waiting %ss before restart" % (self.root_resource_id, retry_delay))
                import sys
                import traceback
                exc_info = sys.exc_info()
                backtrace = '\n'.join(traceback.format_exception(*(exc_info or sys.exc_info())))
                daemon_log.warning("Backtrace: %s" % backtrace)

                for i in range(0, retry_delay):
                    if self.stopping:
                        break
                    else:
                        time.sleep(1)

            else:
                daemon_log.info("Session %s: out of scan loop cleanly" % self.root_resource_id)

        daemon_log.info("Session %s: Dropped out of retry loop" % self.root_resource_id)
        self.finished = True

    def _scan_loop(self, plugin_klass, root_resource):
        daemon_log.debug("Session %s: starting scan loop" % root_resource._handle)
        instance = plugin_klass(self.root_resource_id)
        # TODO: impose timeouts on plugin calls (especially teardown)
        try:
            daemon_log.debug("Session %s: >>initial_scan" % root_resource._handle)
            instance.do_initial_scan(root_resource)
            daemon_log.debug("Session %s: <<initial_scan" % root_resource._handle)
            while not self.stopping:
                daemon_log.debug("Session %s: >>periodic_update" % root_resource._handle)
                instance.do_periodic_update(root_resource)
                daemon_log.debug("Session %s: <<periodic_update" % root_resource._handle)

                i = 0
                while i < instance.update_period and not self.stopping:
                    time.sleep(1)
        except Exception:
            raise
        finally:
            instance.do_teardown()

    def stop(self):
        self.stopping = True

class MessageReceiver(threading.Thread):
    def __init__(self, daemon, *args, **kwargs):
        self.stopping = False
        self.daemon = daemon
        super(MessageReceiver, self).__init__(*args, **kwargs)

    def _run_consumer(self):
        from kombu import BrokerConnection, Exchange, Queue
        import settings

        storage_plugin_exchange = Exchange("storage_plugin", "direct", durable = True)
        removal_queue = Queue("removals", exchange = storage_plugin_exchange, routing_key = "removals")

        def handle_recv(body, message):
            self.daemon.remove_resource(body['resource_global_id'])

        with BrokerConnection("amqp://%s:%s@%s:%s/%s" % (settings.BROKER_USER, settings.BROKER_PASSWORD, settings.BROKER_HOST, settings.BROKER_PORT, settings.BROKER_VHOST)) as conn:
            conn.connect()
            removal_queue(conn.channel()).declare()
            with conn.Consumer([removal_queue], callbacks=[handle_recv]):
                while not self.stopping:
                    conn.drain_events()
            return True

    def run(self):
        retry_period = 10
        max_retry_period = 60

        daemon_log.info("Starting MessageReceiver main loop")
        while not self.stopping:
            try:
                self._run_consumer()
            except Exception, e:
                daemon_log.error("Exception %s running AMQP consumer" % e)
                daemon_log.error("Retrying in %d seconds" % retry_period)

                from time import sleep
                i = 0
                while i < retry_period and not self.stopping:
                    sleep(1)
                    i += 1
                if retry_period < max_retry_period:
                    retry_period *= 2
        daemon_log.info("Finished MessageReceiver main loop")

    def stop(self):
        self.stopping = True

class StorageDaemon(object):
    @classmethod
    def request_remove_resource(cls, resource_id):
        from kombu import BrokerConnection, Exchange, Queue
        import settings

        storage_plugin_exchange = Exchange("storage_plugin", "direct", durable = True)
        removal_queue = Queue("removals", exchange = storage_plugin_exchange, routing_key = "removals")

        with BrokerConnection("amqp://%s:%s@%s:%s/%s" % (settings.BROKER_USER, settings.BROKER_PASSWORD, settings.BROKER_HOST, settings.BROKER_PORT, settings.BROKER_VHOST)) as conn:
            removal_queue(conn.channel()).declare()
            with conn.Producer(exchange = storage_plugin_exchange, serializer = 'json', routing_key = 'removals') as producer:
                producer.publish({'resource_id': resource_id})

    def __init__(self):
        self.stopping = False

        self._session_lock = threading.Lock()

        self._all_sessions = {}
        # Map of module name to map of root_resource_id to PluginSession
        self.plugins = {}
        from configure.lib.storage_plugin.manager import storage_plugin_manager
        for p in storage_plugin_manager.loaded_plugins.keys():
            # Create sessions for all root resources
            sessions = {}    
            for srr_id in self.root_resource_ids(p):
                session = PluginSession(srr_id)
                sessions[srr_id] = session
                self._all_sessions[srr_id] = session

            self.plugins[p] = sessions

        session_count = reduce(lambda x,y: x+y, [len(s) for s in self.plugins.values()])
        daemon_log.info("StorageDaemon: Loaded %s plugins, %s sessions" % (len(self.plugins), session_count))

    def remove_resource(self, resource_id):
        # Is there a session to kill?
        kill_session = None
        daemon_log.info("StorageDaemon: removing %s" % resource_id)
        with self._session_lock:
            try:
                kill_session = self._all_sessions[resource_id]
            except KeyError:
                pass

            if kill_session != None:
                kill_session.stop()
                daemon_log.info("StorageDaemon: waiting for session to stop")
                from time import sleep
                while(not kill_session.stopped):
                    sleep(1)

            from configure.lib.storage_plugin.resource_manager import resource_manager
            resource_manager.global_remove_resource(resource_id)

    def root_resource_ids(self, plugin):
        """Return the PK of all StorageResourceRecords for 'plugin' which have no parents"""
        from configure.lib.storage_plugin.manager import storage_plugin_manager
        # We will be polling, to need to commit to see new data
        with transaction.commit_manually():
            transaction.commit()
            ids = storage_plugin_manager.get_scannable_resource_ids(plugin)
            transaction.commit()
        return ids

    def main_loop(self):
        daemon_log.info("StorageDaemon: entering main loop")
        for scannable_id, session in self._all_sessions.items():
            session.start()

        while not self.stopping:
            time.sleep(5)

            # Look for any new root resources and start sessions for them
            with self._session_lock:
                for plugin,sessions in self.plugins.items():
                    for rrid in self.root_resource_ids(plugin):
                        if not rrid in sessions:
                            daemon_log.info("StorageDaemon: new session for resource %s" % rrid)
                            s = PluginSession(rrid)
                            sessions[rrid] = s
                            self._all_sessions[rrid] = s
                            s.start()
        
        daemon_log.info("StorageDaemon: leaving main loop")

        self._stop_sessions()

    def _stop_sessions(self):
        daemon_log.info("StorageDaemon: stopping sessions")
        for scannable_id, session in self._all_sessions.items():
            session.stop()
        daemon_log.info("StorageDaemon: joining sessions")
        for scannable_id, session in self._all_sessions.items():
            session.join()

    def stop(self):
        self.stopping = True

if __name__ == '__main__':
    daemon = StorageDaemon()

    # Respond to Ctrl+C
    def signal_handler(signal, frame):
        daemon_log.info("__main__: Stopping...")
        daemon.stop()
    signal.signal(signal.SIGINT, signal_handler)

    try:
        daemon.main_loop()
    except Exception, e:
        import sys
        import traceback
        exc_info = sys.exc_info()
        backtrace = '\n'.join(traceback.format_exception(*(exc_info or sys.exc_info())))
        daemon_log.warning("Exception in main loop.  backtrace: %s" % backtrace)
        os._exit(-1)


