#!/usr/bin/env python
#
# ==============================
# Copyright 2011 Whamcloud, Inc.
# ==============================

import sys
import os
bin_dir = os.path.abspath(os.path.dirname(sys.modules['__main__'].__file__))
project_dir = "/" + os.path.join(*(bin_dir.split(os.sep)[0:-2]))
sys.path.append(project_dir)

from django.core.management import setup_environ
import settings
setup_environ(settings)

import signal
import logging
import os
import threading
import time
import datetime
from django.db import transaction

daemon_log = logging.getLogger('storage_daemon')
daemon_log.setLevel(logging.DEBUG)
handler = logging.FileHandler(os.path.join(settings.LOG_PATH, "storage_daemon.log"))
handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%d/%b/%Y:%H:%M:%S'))
daemon_log.addHandler(handler)
if settings.DEBUG:
    daemon_log.setLevel(logging.DEBUG)
    daemon_log.addHandler(logging.StreamHandler())
else:
    daemon_log.setLevel(logging.WARNING)

# Thread-per-session is just a convenient way of coding this.  The actual required
# behaviour is for a session to always run in the same process.  So we could
# equally use a thread pool for advancing the loop of each session, or we
# could use a multiprocessing pool as long as a session is always advanced
# in the same worker process.
class PluginSession(threading.Thread):
    def __init__(self, root_resource_id, *args, **kwargs):
        self.stopping = False
        self.root_resource_id = root_resource_id

        super(PluginSession, self).__init__(*args, **kwargs)

    def run(self):
        from configure.lib.storage_plugin import ResourceQuery, storage_plugin_manager
        from configure.models import StorageResourceRecord
        record = StorageResourceRecord.objects.get(id=self.root_resource_id)
        plugin_klass = storage_plugin_manager.get_plugin_class(
                          record.resource_class.storage_plugin.module_name)
        root_resource = ResourceQuery().get_resource(record)

        RETRY_DELAY_MIN = 1
        RETRY_DELAY_MAX = 256
        retry_delay = RETRY_DELAY_MIN
        while not self.stopping:
            last_retry = datetime.datetime.now()
            try:
                self._scan_loop(plugin_klass, root_resource)
            except Exception, e:
                run_duration = datetime.datetime.now()- last_retry
                if last_retry and run_duration > datetime.timedelta(seconds = RETRY_DELAY_MAX):
                    # If the last run was long running (i.e. probably ran okay until something went
                    # wrong) then retry quickly.
                    retry_delay = RETRY_DELAY_MIN
                else:
                    # If we've already retried recently, then start backing off.
                    retry_delay *= 2

                daemon_log.warning("Exception in scan loop for resource %s, waiting %ss before restart" % (self.root_resource_id, retry_delay))
                import sys
                import traceback
                exc_info = sys.exc_info()
                backtrace = '\n'.join(traceback.format_exception(*(exc_info or sys.exc_info())))
                daemon_log.warning("Backtrace: %s" % backtrace)

                for i in range(0, retry_delay):
                    if self.stopping:
                        break
                    else:
                        time.sleep(1)

            else:
                daemon_log.info("Session %s: out of scan loop cleanly" % self.root_resource_id)

        daemon_log.info("Session %s: Dropped out of retry loop" % self.root_resource_id)

    def _scan_loop(self, plugin_klass, root_resource):
        daemon_log.debug("Session %s: starting scan loop" % root_resource._handle)
        instance = plugin_klass(self.root_resource_id)
        instance.do_initial_scan(root_resource)
        while not self.stopping:
            instance.do_periodic_update(root_resource)
            time.sleep(instance.update_period)

    def stop(self):
        self.stopping = True

class StorageDaemon(object):
    def __init__(self, plugins):
        self.stopping = False

        # Map of module name to map of root_resource_id to PluginSession
        self.plugins = {}
        for p in plugins:
            # Load the plugin
            from configure.lib.storage_plugin import storage_plugin_manager 
            storage_plugin_manager.load_plugin(p)

            # Create sessions for all root resources
            sessions = {}    
            for srr_id in self.root_resource_ids(p):
                sessions[srr_id] = PluginSession(srr_id)

            self.plugins[p] = sessions

        session_count = reduce(lambda x,y: x+y, [len(s) for s in self.plugins.values()])
        daemon_log.info("StorageDaemon: Loaded %s plugins, %s sessions" % (len(self.plugins), session_count))

    def root_resource_ids(self, plugin):
        """Return the PK of all StorageResourceRecords for 'plugin' which have no parents"""
        from configure.lib.storage_plugin import storage_plugin_manager
        # We will be polling, to need to commit to see new data
        with transaction.commit_manually():
            transaction.commit()
            records = storage_plugin_manager.get_scannable_resource_ids(plugin)
        for r in records:
            yield r['id']

    def all_sessions(self):
        for session_map in self.plugins.values():
            for session in session_map.values():
                yield session

    def main_loop(self):
        daemon_log.info("StorageDaemon: entering main loop")
        for session in self.all_sessions():
            session.start()

        while not self.stopping:
            time.sleep(5)

            # Look for any new root resources and start sessions for them
            for plugin,sessions in self.plugins.items():
                for rrid in self.root_resource_ids(plugin):
                    if not rrid in sessions:
                        daemon_log.info("StorageDaemon: new session for resource %s" % rrid)
                        s = PluginSession(rrid)
                        sessions[rrid] = s
                        s.start()
        
        daemon_log.info("StorageDaemon: leaving main loop")

        self._stop_sessions()

    def _stop_sessions(self):
        daemon_log.info("StorageDaemon: stopping sessions")
        for session in self.all_sessions():
            session.stop()
        daemon_log.info("StorageDaemon: joining sessions")
        for session in self.all_sessions():
            session.join()

    def stop(self):
        self.stopping = True

if __name__ == '__main__':
    daemon = StorageDaemon(settings.INSTALLED_STORAGE_PLUGINS)

    # Respond to Ctrl+C
    def signal_handler(signal, frame):
        daemon_log.info("__main__: Stopping...")
        daemon.stop()
    signal.signal(signal.SIGINT, signal_handler)

    try:
        daemon.main_loop()
    except Exception, e:
        daemon_log.error("Exception in main loop, terminating")
        daemon_log.error(e)
        os._exit(-1)


