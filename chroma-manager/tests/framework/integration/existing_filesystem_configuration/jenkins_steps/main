#!/bin/bash -ex

PROVISIONER=${PROVISIONER:-"ssh chromatest@autotest ./provisionchroma -v -S"}

. chroma-manager/tests/framework/integration/utils/defaults.sh

cd $WORKSPACE
# Copy a fingerprinted file so we can link together the projects in jenkins.
set +x  # DONT REMOVE/COMMENT or you will risk exposing the jenkins-pull api token in the console logs.
curl -k -O -u $JENKINS_USER:$JENKINS_PULL "$JOB_URL/chroma-bundles/ieel-$IEEL_VERSION.tar.gz"
set -x

sed -i -e "s/BUILD_JOB_NAME/${BUILD_JOB_NAME}/g" \
       -e "s/BUILD_JOB_BUILD_NUMBER/${BUILD_JOB_BUILD_NUMBER}/g" \
       -e "s/TEST_DISTRIBUTION/${TEST_DISTRIBUTION}/g" \
       chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/existing_filesystem_configuration_cluster_cfg.json

python chroma/chroma-manager/tests/framework/utils/provisioner_interface/test_json2provisioner_json.py chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/existing_filesystem_configuration_cluster_cfg.json provisioner_input.json

cat provisioner_input.json
echo

# Release the provisioned cluster (at exit of this script)
trap "set +e
# Gather logs from nodes
python chroma/chroma-manager/tests/integration/utils/chroma_log_collector.py $WORKSPACE/test_logs existing_filesystem_configuration_cluster_cfg.json

sed -e 's/provision\": *true/provision\": false/g' < provisioner_output.json | $PROVISIONER" EXIT

# Provision cluster to run tests on
PROVISION_START_TIME=$(date '+%s')
cat provisioner_input.json | $PROVISIONER > provisioner_output.json
PROVISION_END_TIME=$(date '+%s')
PROVISION_DURATION=$(( $PROVISION_END_TIME-$PROVISION_START_TIME ))
echo "$PROVISION_DURATION" > $WORKSPACE/provision_duration.txt
echo "Provision took $(( $PROVISION_DURATION/60 )) minutes."

cat provisioner_output.json
echo

if ! grep '"success":true' provisioner_output.json; then
    echo "Cluster provisioner failed"
    cat provisioner_output.json
    exit 1
fi

python chroma/chroma-manager/tests/framework/utils/provisioner_interface/provisioner_json2test_json.py provisioner_output.json existing_filesystem_configuration_cluster_cfg.json
cat existing_filesystem_configuration_cluster_cfg.json

# see if this cures the 401 errors from jenkins
eval $(python chroma/chroma-manager/tests/utils/json_cfg2sh.py existing_filesystem_configuration_cluster_cfg.json)
pdsh -R ssh -l root -S -w $(spacelist_to_commalist ${STORAGE_APPLIANCES[@]} ${WORKERS[@]} $CHROMA_MANAGER $TEST_RUNNER) "exec 2>&1; set -xe
if [ -f /etc/yum.repos.d/autotest.repo ]; then
    set +x
    sed -i -e 's/Aitahd9u/$JENKINS_PULL/g' /etc/yum.repos.d/autotest.repo
    set -x
fi
pushd /etc/yum.repos.d/
for f in *.repo; do
  sed -i -e 's/distro=[^\/][^\/]*/distro=el6.4/' -e 's/http:\/\/jenkins-pull/https:\/\/jenkins-pull/g' \$f
done
popd

# Disable EPEL
yum-config-manager --disable EPEL-6-x86_64" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

echo "Beginning automated test run..."
export MEASURE_COVERAGE
export JENKINS_PULL


echo "Beginning automated efs run..."
ORIGINAL_CLUSTER_CONFIG=$(ls $PWD/existing_filesystem_configuration_cluster_cfg.json)
chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/cluster_setup

for dne in true false; do
    for test_ha in true false; do
        if $test_ha; then
            device_types_to_test=(linux)
        else
            #devices_to_test=(zfs lvm mdraid linux); do  <--- mdraid Coming soon.
            device_types_to_test=(zfs lvm linux)
        fi

        for device_type in ${device_types_to_test[@]}; do
            echo "Beginning automated ${device_type} run..."

            export CLUSTER_CONFIG=$PWD/existing_filesystem_configuration_cluster_cfg_${device_type}_HA_is_${test_ha}_dne_is_${dne}.json

            sed -e s/\"device_type\"\:\ \"linux\"/\"device_type\":\ \"${device_type}\"/g $ORIGINAL_CLUSTER_CONFIG > $CLUSTER_CONFIG
            sed -i -e s/\"test_ha\"\:\ true/\"test_ha\":\ ${test_ha}/g $CLUSTER_CONFIG

            # One Kind entry is defined as "kind": "OSTorMDT" set it to be an OST for !dne or an MDT for dne
            # The replace actually does a number of things such as the mount point etc.
            if $dne; then
                sed -i -e s/OSTorMDT/MDT/g $CLUSTER_CONFIG
                sed -i -e s/ostORmdt/mdt/g $CLUSTER_CONFIG
            else
                sed -i -e s/OSTorMDT/OST/g $CLUSTER_CONFIG
                sed -i -e s/ostORmdt/ost/g $CLUSTER_CONFIG
            fi

            export XML_RESULTS_FILE="~/test_report_${device_type}_HA_is_${test_ha}.xml"

            # Don't stop on error for this case because if one iteration of this loop fails we still want to perform the other iterations
            set +e
            chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/filesystem_setup
            cat $CLUSTER_CONFIG
            chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/run_tests
            set -e

            echo "Automated ${device_type} run complete."
        done
    done
done

echo "Automated efs run complete."

# Combine coverage reports from the different nodes.
if $MEASURE_COVERAGE; then
  ls .coverage*
  echo "
[paths]
source1 =
    $WORKSPACE/chroma/chroma-manager/
    /usr/share/chroma-manager/
source2 =
    $WORKSPACE/chroma/chroma-agent/chroma_agent/
    /usr/lib/python2.6/site-packages/chroma_agent/

[report]
include =
    $WORKSPACE/chroma/*
omit =
    *junk.py
    */tests/*
" > .coveragerc

  coverage combine
  coverage report -m
  coverage xml --ignore-errors
fi
