#!/bin/bash -ex

. chroma-manager/tests/framework/integration/utils/defaults.sh

cd $WORKSPACE
# Copy a fingerprinted file so we can link together the projects in jenkins.
set +x  # DONT REMOVE/COMMENT or you will risk exposing the jenkins-pull api token in the console logs.
curl -k -O -u $JENKINS_USER:$JENKINS_PULL "$JOB_URL/chroma-bundles/ieel-$IEEL_VERSION.tar.gz"
set -x

sed -i -e "s/BUILD_JOB_NAME/${BUILD_JOB_NAME}/g" \
       -e "s/BUILD_JOB_BUILD_NUMBER/${BUILD_JOB_BUILD_NUMBER}/g" \
       -e "s/TEST_DISTRIBUTION/${TEST_DISTRIBUTION}/g" \
       chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/existing_filesystem_configuration_cluster_cfg.json

python chroma/chroma-manager/tests/framework/utils/provisioner_interface/test_json2provisioner_json.py chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/existing_filesystem_configuration_cluster_cfg.json provisioner_input.json

# don't really need a client configured so let's save the time doing it
sed -i -e '/lustre_client_version/c\
            "lustre_client_version": ""' provisioner_input.json

cat provisioner_input.json
echo

# Release the provisioned cluster (at exit of this script)
trap "set +e
set -x
# Gather logs from nodes
python chroma/chroma-manager/tests/integration/utils/chroma_log_collector.py $WORKSPACE/test_logs existing_filesystem_configuration_cluster_cfg.json

sed -e 's/provision\": *true/provision\": false/g' < provisioner_output.json | $PROVISIONER" EXIT

# Provision cluster to run tests on
PROVISION_START_TIME=$SECONDS
rc=0
cat provisioner_input.json | $PROVISIONER > provisioner_output.json || rc=$?
PROVISION_END_TIME=$SECONDS
PROVISION_DURATION=$((PROVISION_END_TIME-PROVISION_START_TIME))
echo "$PROVISION_DURATION" > $WORKSPACE/provision_duration.txt
echo "Provision took $((PROVISION_DURATION/60)) minutes."

cat provisioner_output.json
echo

if [ $rc != 0 ] || [ ! -s provisioner_output.json ] || grep '"success": false' provisioner_output.json; then
    echo "Cluster provisioner failed"
    cat provisioner_output.json
    exit 1
fi

python chroma/chroma-manager/tests/framework/utils/provisioner_interface/provisioner_json2test_json.py provisioner_output.json existing_filesystem_configuration_cluster_cfg.json
cat existing_filesystem_configuration_cluster_cfg.json

# see if this cures the 401 errors from jenkins
eval $(python chroma/chroma-manager/tests/utils/json_cfg2sh.py existing_filesystem_configuration_cluster_cfg.json)
pdsh -R ssh -l root -S -w $(spacelist_to_commalist ${STORAGE_APPLIANCES[@]} ${WORKERS[@]} $CHROMA_MANAGER $TEST_RUNNER) "exec 2>&1; set -xe
if [ -f /etc/yum.repos.d/autotest.repo ]; then
    set +x
    sed -i -e 's/Aitahd9u/$JENKINS_PULL/g' /etc/yum.repos.d/autotest.repo
    set -x
fi
pushd /etc/yum.repos.d/
for f in *.repo; do
  sed -i -e 's/distro=[^\/][^\/]*/distro=el6.4/' -e 's/http:\/\/jenkins-pull/https:\/\/jenkins-pull/g' \$f
done
popd

# Disable EPEL
yum-config-manager --disable EPEL-6-x86_64" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

echo "Beginning automated test run..."
export MEASURE_COVERAGE
export JENKINS_PULL


echo "Beginning automated efs run..."
ORIGINAL_CLUSTER_CONFIG=$(ls $PWD/existing_filesystem_configuration_cluster_cfg.json)
chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/cluster_setup

setup_rc=0
for dne in true false; do
    for test_ha in true false; do
        if $test_ha; then
            device_types_to_test=(linux)
        else
            #devices_to_test=(zfs lvm mdraid linux); do  <--- mdraid Coming soon.
            device_types_to_test=(zfs lvm linux)
        fi

        for device_type in ${device_types_to_test[@]}; do
            echo "Beginning automated ${device_type} run..."

            export CLUSTER_CONFIG=$PWD/existing_filesystem_configuration_cluster_cfg_${device_type}_HA_is_${test_ha}_dne_is_${dne}.json

            sed -e "s/\(\"device_type\": *\)\"linux\"/\1\"${device_type}\"/g" $ORIGINAL_CLUSTER_CONFIG > $CLUSTER_CONFIG
            sed -i -e "s/\(\"test_ha\"\: *\)true/\1${test_ha}/g" $CLUSTER_CONFIG

            # One Kind entry is defined as "kind": "OSTorMDT" set it to be an OST for !dne or an MDT for dne
            # The replace actually does a number of things such as the mount point etc.
            if $dne; then
                sed -i -e s/OSTorMDT/MDT/g $CLUSTER_CONFIG
                sed -i -e s/ostORmdt/mdt/g $CLUSTER_CONFIG
            else
                sed -i -e s/OSTorMDT/OST/g $CLUSTER_CONFIG
                sed -i -e s/ostORmdt/ost/g $CLUSTER_CONFIG
            fi

            export XML_RESULTS_FILE="~/test_report_${device_type}_HA_is_${test_ha}.xml"

            # Don't stop on error for this case because if one iteration of this loop fails we still want to perform the other iterations
            cat $CLUSTER_CONFIG
            if ! chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/filesystem_setup; then
                let setup_rc+=${PIPESTATUS[0]}
                echo "Automated ${device_type} setup failed"
                continue
            fi
            if ! chroma/chroma-manager/tests/framework/integration/existing_filesystem_configuration/run_tests; then
                let test_run_rc+=${PIPESTATUS[0]}
                echo "Automated ${device_type} run failed"
                continue
            fi
            echo "Automated ${device_type} run complete."
        done
    done
done

if [ $setup_rc > 0 -o $test_run_rc > 0 ]; then
    echo "One or more iterations failed"
    exit 1
fi

echo "Automated efs run complete."

# Combine coverage reports from the different nodes.
if $MEASURE_COVERAGE; then
  ls .coverage*
  echo "
[paths]
source1 =
    $WORKSPACE/chroma/chroma-manager/
    /usr/share/chroma-manager/
source2 =
    $WORKSPACE/chroma/chroma-agent/chroma_agent/
    /usr/lib/python2.6/site-packages/chroma_agent/

[report]
include =
    $WORKSPACE/chroma/*
omit =
    *junk.py
    */tests/*
" > .coveragerc

  coverage combine
  coverage report -m
  coverage xml --ignore-errors
fi
